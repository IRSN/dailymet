---
author: "Yves Deville [deville.yves@alpestat.com](deville.yves@alpestat.com)"
title: "R Package `dailymet`: Overview"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{R Package `dailymet`: Overview}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
linkcolor: blue
---

# Goals

- Use daily meteorological timeseries, mainly `TX`. 

- Provide bases of functions of the date: trigonometric, polynomial, ...

- Fit time-varying and non-stationary *POT models* with emphasis on
the sensitivity to the *threshold choice*, thanks to dedicated classes
of objects that we may call "TLists" for *list by threshold*.


# Data classes and data manipulation functions

## The `"dailyMet"` data class

As its name may suggest the `"dailyMet"` S3 class contains objects
descirbing meteorological timeseries sampled on a daily basis. 
The package comes with the `Rennes` example.


```{r Rennes, message=FALSE} 
library(dailymet)
Rennes
```

The `print` method used for `Rennes` shows the summary above which 
provides the essential information.


```{r Rennes0, message=FALSE} 
class(Rennes)
methods(class = "dailyMet")
```

So `Rennes` has class `"dailyMet"` which inherits from the
`"data.frame"`class. The `print` method provides useful information. A
method which is not implemented for the class `"dailyMet"` will be
inherited from the `"data.frame"` class e.g., `head`, `tail`, `nrow`
...


```{r Rennes2, fig.width=8, fig.height=6} 
autoplot(Rennes)

```

Since the object embeds several variables related to the date, we can
use these straightforwardly. Mind that the variable names are
capitalised.

```{r Rennes3, message=FALSE, fig.width=8, fig.height=6} 
autoplot(Rennes, subset = Year >= 2010 & JJA, group = "year")

``` 

Splitting the timeseries in years is suitable when the interest is on
the summer season. It the interest is instead on winter, then using
the "winter year" `YearW` will be better since the whole winter is
included in a same "year".


```{r Rennes4, fig.width=8, fig.height=6} 
autoplot(Rennes, subset = Year >= 2010, group = "yearW")

```

## Creating `dailyMet` objects from data files

Although no other data is shipped with the package, **dailymet** has a
sketch of file-based database, based on the information provided in
`stationsMF`

```{r stations, message=FALSE} 
findStationMF("troy")
```

The idea is that the name or description can be quite loose. The
reliable identifier of a station is given in `Code`, which corresponds
to Météo-France [données publiques
Météo-France](https://donneespubliques.meteofrance.fr/)


```{r stations2, message=FALSE} 
head(stationsMF)
```
We will focus on the French metropolitan area.


```{r stations3, echo=FALSE, message=FALSE,fig.width=6, fig.height=6} 
library(leaflet)
m <- leaflet() %>% addTiles;
## m <- m %>% fitBounds(lng1 = -4.5, lat1 = 41.9, lng2 = 7.9, lat2 = 50.8)
m <- m %>% setView(2, 47.1, zoom = 5)
m <- m %>% addMarkers(lng = stationsMF[ , "Lon"],
lat = stationsMF[ , "Lat"],
popup = stationsMF[ , "ShortName"])
m
```

See the help `stationsMF` for a **leaflet** map of these. Note that
the codes of the main MF stations for the metropolitan area correspond
rougthly to an ordering from North to South (decreasing latitude) and
West to East (increasing longitude). This can be of some help.

Provided that the data is available in `.csv` files suitably named, we
can read these into `dailyMet` objects. The function `readMet` can be
used for that aim. In order to avoid a tedious construction of
filenames an automated naming is used. For instance the full
information for MF station *Troyes* (actually at the *Troyes-Barberey*
airport) is found in the  list returned by `findStationMF`. This list 
can be passed as the first argument of the `readMet` function, which 
will build the filename from the values of the `Id` and `Name` fields. The 
file is to be found in a directory with its name stored in the environment 
variable `metData`. 

```{r stations4}
## fails: several stations match
try(findStationMF("tro"))
myStation <- findStationMF("troyes")
try(readMet(myStation))
Sys.setenv(metData = "~/Bureau/climatoData")
try(Troyes <- readMet(myStation))
```
Although the file is not found, we now see the name of the file that is seeked
for.

# Functions and classes for analyses and models

## Using *TList*s

### What are TLists?

A T-list or \emph{TList} is a list of objects sharing the same
definition except for their threshold. The threshold is related to a
probability `tau` corresponding to the probability $\tau$ as used in
quantile regression.

- A `rqTList` object is a list of `rq` objects differing only by their
  probability `tau`, hence related to the same data, same formula, ...

- A `fevdTList`object is a list of `fevd` objects representing
  Poisson-GP POT models differing *only by their threshold* which is
  given by quantile regression and corresponds to different
  probabilities `tau`. Again the `fevd`objects are related to the same
  data, to the same formulas, ...
  
Implicitly assumed, the vector `tau` should be in strictly increasing
order.

Another *TList* class is the `"pgpTList"` class which corresponds to a
list of fitted Poisson-GP models. Mind that consistenty whith `rq` and
`fevd` a lower cas acronym is used, followed by `"TLIst`". However for
now the class `pgp` does not exist. We can fit a `pgpTList` object
with a vector `tau` of length one if needed. A `pgpTList` object is
quite similar to a `fevdList` object. The main difference concerns the
exceedances and their occurrence in time: Instead of an assuming
constant rate $\lambda$, a purely temporal non-homogeneous Poisson
process is used. A rate depending on the time $\lambda(t)$ or on the
time and other covariates $\lambda(x, \mathbf{x})$ can be specified by
using a devoted formula for $\log \lambda$.

**Caution** The development of `pgpTList` class and of the relevant
methods is far from being achieved. Some major changes are likely to occur.




### Some important remarks

- A `rq` object does not encode a full distribution nor even a tail
  distribution. The `rq` objects may fail to be consistent and the
  quantile may fail to increase with the probability $\tau$. See XXX
  Northrop.

- Stricly speaking, the `fevd` objects in a `fevdTList` object are
  *different* Poisson-GP models, although they must have the same
  formulas. Indeed, the Poisson-GP parameterisation is not independent
  of the threshold: if the GPD scale depends linearly of a covariate
  $x$ for a given threshold $u$, then for a higher threshold $u'>u$
  the scale will generally depend on $x$ in a nonlinear fashion. See
  the relation between the two POT parameterisation Poisson-GP and
  NHPP, only the later being independent of the threshold.

## Quantile regression for seasonality

```{r rqTList0, message=FALSE, fig.width=8, fig.height=6} 
Rq <- rqTList(dailyMet = Rennes)
tau(Rq)
formula(Rq)
autoplot(Rq)

```

By default the creator `rqTList`


- Uses some defined probabilities $\tau$ for the quantiles?. These can
  be assessed by the `tau` method.

- Uses a `formula` which defines a yearly seasonality for the
  quantiles. The default formula uses a base of trigonometric
  functions with 3 harmonics, corresponding the the fundamental
  frequency $1/365.25\:\text{day}^{-1}$ and its integer multiples 
  $2/365.25$, $3/365.25$, ...

- Considers a "design" function which creates the required variables
  `cosj1` , `sinj1`, `cosj2`, `sinj2`, ... where the integer after the
  prefix `cos` of `sin` gives the frequency in increasing order,
  \code{1} standing for the fundamental frequency corresponding to the
  one-year period.

- Build the required variables from the existing variables in the
  object specified by `dailyMet`, mainly from the `Date` column.

- Fits quantile regression `rq` objects from the **quantreg** package

More precisely the quantile $q(\tau)$ of the meteorological variable is
considered as a trigonometric polynomial function $q_d(\tau)$ of the
day in the year a.k.a Julian day $d$ ($1 \leqslant d \leqslant 366$)

\begin{equation}
\tag{1}
q_d(\tau) \approx  \alpha_0^{q}(\tau) + \sum_{k=1}^K \alpha_k^{q}(\tau) \cos\{2\pi k d/D\} +
	\beta_k^{q}(\tau) \sin\{2\pi k d/D\} 
\end{equation}

where $D:=365.25$ is yearly period expressed in days. The
pseudo-exponent $q$ in the coefficients $\alpha$ and $\beta$ is used
to recall that they describe a quantile. The default number of
harmonics $K$ is $3$. The quantile regression provides the estimated
coefficients $\hat{\alpha}_k^{q}(\tau)$ and $\hat{\beta}_k^{q}(\tau)$.



```{r rqTList1, message=FALSE, fig.width=8, fig.height=6} 
methods(class = "rqTList")
coef(Rq)
coSd(Rq)

``` 

The `coSd` method (for "coef" and "Standard error" or "Standard
deviation") gives the coefficients and their standard error. We see
that some estimated coefficients are not significant, namely those for
the 3-rd harmonic for the "small" probablities. However, when $\tau$
becomes larger, the estimated coefficients for the $3$-rd harmonic
becomes significant, although their standard error increases because
they are based on a smaller number of observations. This suggests that
the $3$-rd harmonic plays a role in the seasonality of the extremes,
although it will be difficult to assess.


As may be guessed from the plot of quantiles, the fitted phases
corresponding to the different harmonics are quite similar across
probabilities $\tau < 0.95$. More precisely we may consider the following
alternative parameterisation of the trigonometric polynomial

\begin{equation}
   \tag{2}
   q_d(\tau) \approx 
	\gamma_0^{q}(\tau) + \sum_{k=1}^K 
	\gamma_k^{q}(\tau) \sin\left\{2\pi k \left[d - \phi_k^{q}(\tau)\right]/D\right\} 
	
\end{equation}

where the parameter $\gamma_k^{q}(\tau)$ and $\phi_k^{q}(\tau)$ are
called *amplitudes* and *phase shifts* or simply *phases*. The two
formulations (1) and (2) are actually equivalent, as can be seen from
the trigonometric "angle subtraction formula" $\sin(a -b) =
\sin(a)\cos(b) - \cos(a) \sin(b)$. We could think of using the second
form in a `quanteg::rq` fit, but this is not possible since the phase
$\phi_k^q$ apears in a nonlinear fashion. So we can fit the linear
cos-sin form and then compute the estimate for the amplitudes an
phases by using some trigonometry.


```{r rqTList2, message=FALSE} 
co <- coef(Rq)
phases(co)
``` 

The table shows the $K=3$ phases $\phi_k$ and amplitudes $\gamma_k$. Note that
the object returned by `phases` has as special class `"phasesMatrix"`. The 
amplitudes are actually stored as an attribute of the numeric matrix of phases,
not as a matrix with $2K$ columns.

We see that for the different probabilities the phases of the $1$-st and $2$-nd
harmonics are quite similar, while those of the $3$-rd harmonics are different, 
and seem to drift as the probability $\tau$ increases.

```{r rqTList3, message=FALSE, fig.width=8, fig.height=6} 
autoplot(phases(co))

``` 

The constant $\gamma_0^{[\tau]}$ does not apear on the plot..  Note
that the amplitudes $\gamma_k^{[\tau]}$ rapidly decrease with the
frequency, consistently with the fact that the quantiles are quite
smooth functions of the day $d$. The amplitude slightly increases with
$\tau$, especially for the fundamental frequency $k=1$.  In other
words the seasonality becomes more pronounced when the probability $\tau$
increases.


## Seasonality in (time-varying) POT models

### Why seasonality matters
Using a suitable description of the seasonality is a major concern in
POT modeling. Concerning our meteorological variables, a natural idea
is to use GP or GEV parameters depending on the date through the
Julian day $d$ since it is clear that the margnal distibution depends
hevily on $d$.

There are also many reasons to use a seasonaly time-varying
threshold $u(d)$ depending as well on $d$. One motivation is the
efficiency of the estimation: A constant threshold would be too low
season and too high for another. Moreoved, if a constant threshold is
used, the results are likely to depend much on the threshold value
because the distribution over a period of several months in the year
is actually a weighted mixture of different distributions
corresponding to the values of $d$, and their weight will depend much
on the constant threshold. For instance, if a constant threshold is
used for all the JJA period, the weight of the early June and late
August will be smaller when the threshold is increased.

### Poisson-GP models

In order to describe the yearly seasonality, a natural idea is to use
a trigonometric polynomial as described above. For instance the GP
scale parameter $\sigma$ could depend on the Julian day $d$ as in

$$
 \sigma_d = \alpha_0^{\sigma} + \sum_{k=1}^K \alpha_k^{\sigma} \cos\{2\pi k d/D\} +
	\beta_k^{\sigma} \sin\{2\pi k d/D\}
$$

where the coefficients $\alpha_k^{\sigma}$ and $\beta_k^{\sigma}$
are to be estimated.  However $2 K +1$ parameters and for $K=3$ or
even for $K=2$ the estimation can be difficult. To facilitate the
estimation, one can use instead the amplitude-phase formulation

$$
   \sigma_d = 
	\gamma_0^{\sigma} + \sum_{k=1}^K 
	\gamma_k^{\sigma} \sin\left\{2\pi k \left[d - \phi_k \right]/D\right\} 
$$

where *the phases $\phi_k$ are considered as fixed* or known. In
practice, we can use the phases $\phi_k :=
{\hat{\phi}}^{q}_k(\tau_{\text{ref}})$ given by quantile regression
for a fixed "reference" probability e.g., $\tau_{\text{ref}} =
0.95$. So we have only $K+1$ parameter to estimate. Since the phases
are usually quite stable for the high quantiles, hopefully the same
should be true also for the GP parameters.

The `"fevdTlist"` is a transitional class which requires to "manually"
create a list of `fevd` objects having the same but different
thresholds obtained by quantile regression. Once these objects have
been fitted and gathered in a list, the `as.fevdTList` coercion method
can be used. The `"pgpTList"` class is easier to use.

Note that while using as above a large range of probability $\tau$ is
adequate to get insights on the variable, a narrower range of
probability values seems more adequate for POT models. We can use
$\tau$ ranging, say, from $0.90$ to $0.98$.

To create a `pgpTList` object, the appropriate way is *first, fit a
`rqTList` object* with chosen thresholds. This object will be passed
to the `thresholds` argument of the creator `pgpTList`. 
In order to compute the sine wave basis functions with the prescribed
phases corresponing to the probability $\tau_{\text{ref}}$, the
argument `tauRef` can be used. 

```{r pgp, message=FALSE, results ="hide", fig.width=8, fig.height=6}
Rq <- rqTList(dailyMet = Rennes, tau = c(0.94, 0.95, 0.96, 0.97, 0.98, 0.99))
Pgp1 <- pgpTList(dailyMet = Rennes, thresholds = Rq,
                declust = TRUE, fitLambda = TRUE, logLambda.fun = ~ YearNum - 1)
p <- predict(Pgp1, lastFullYear = TRUE)
autoplot(p, facet = FALSE)
``` 

The output of the code was not shown because the
`NHPoisson::fitPP.fun` function used to fit the time part of the model
is very verbose.  The Figure above shows the 100-year return level
(RL), which depends on the date, for the last full year of the fitting
period. We see that rather realistic values are obtained and moreover
that the fitted RL depends little on the threshold choice, which is a
nice feature. The default formulas used in the creator for the GP part (hence 
passed to `fevd`)  are

- `scale.fun = ~Cst + sinjPhi1 + sinJPhi2 + sinjPhi3 - 1` 

- `shape.fun = ~1`

So no time-trend was specified in the GP part of the model. However
a time-trend was used for the exceedance rate, namely
$$
   \lambda(t) = \exp\{ \beta_0^\lambda + \beta_1^\lambda t \},
$$
where the time $t$ is given by `YearNum` so the coefficient 
$\beta^\lambda_1$ is in inverse years $\text{yr}^{-1}$.

## How `pgpTList` works

The value of `tauRef` is used to select the appropriate line in the
matrix `phases(coef(thresholds))` which is used internally. So
`tauRef` must correspond to a probability used to define the
thresholds. The so-created vector of phases `phi` is then used to
create the basis functions with the `sinBasis` function or
equivalently of the `tsDesign` function with `type = "sinwave"`.  The
sine wave basis functions are used to add new variables to the data
frame given in `dailyMet`. Then the "fitting functions"
`extRemes::fevd` and `NHPoisson:fitPP.fun` are used to fit the "GP"
part" and the (temporal) "Poisson part" for each of the thresholds
computed from the `thresholds` object. The results for the "GP" part
and the the time Poisson part are stored as tyhe two elements `"GP"`
and `"timePoisson"` of the returned list, the first having the class
`"fevdTList"`. We hence can use the methods for the `"fevdTList"`
class to get insigths on the `"GP"` partof our `pgpTList` object.

**Caution** The log-likelihood of a Poisson-GP is the sum of two
contributions corresponding to the GP and the time-Poisson parts, see
Northrop et Al.



```{r phases, message=FALSE} 
Phi <- phases(coef(Rq))

``` 




# Appendix

## Technical issues

### Related to **quantreg**

- An `rq` object as created by `quantreg::rq` does not store the data
  used.
  
- Coping with missing value `NA` is difficult because the default
  prediction corresponds to `na.omit` which removes the observations
  with `NA` response.

### Related to **extRemes**

- An object with class `"fevd"` corresponding to a Poisson-GP POT
  model does not fit the "time part" of the process. The is usually no
  reason to assume that the exceedance rate is constant.

- An object with class `"fevd"` corresponding to a Poisson-GP POT
  model does not store the value of the threshold as required to make
  a prediction on a new data. Consequently the `predict` method for
  the `"fevd"` class as implemented in **dailymet** is unreliable
  because an attempt is made to find the threshold from the stored
  `call`, but the correponding objects are most often not found.
  
### Related to **HHPoisson**

- There is no formula interface for `fitPP.fun`. The covariates are
  given in a numeric matrix. The coefficients do not have appeling
  names and the order of the columns in the matrix of covariates
  matters.

- The class `"mlePP"` corresponing to the objects created by
  `fitPP.mle` does not have a `predict` method.
